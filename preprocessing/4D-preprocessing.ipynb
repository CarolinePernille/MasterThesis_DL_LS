{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import nibabel as nib\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from preprocessing_utils import calc_mean_std_tensor, preprocess_scale_epi\n",
    "\n",
    "# Model\n",
    "from pytorch3dunet.unet3d import model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')\n",
    "\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    # Set seed for reproducibility\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the model with the weights from the best 3D model\n",
    "\n",
    "Training data for the 4D-UNet were model predictions from the best performing 3D-UNet. Starting by initializing the 3D-UNet with the weights saved during training, and setting the model into evaluation mode, before generating predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet3D(\n",
       "  (encoders): ModuleList(\n",
       "    (0): Encoder(\n",
       "      (basic_module): DoubleConv(\n",
       "        (SingleConv1): SingleConv(\n",
       "          (groupnorm): GroupNorm(1, 2, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(2, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (SingleConv2): SingleConv(\n",
       "          (groupnorm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Encoder(\n",
       "      (pooling): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (basic_module): DoubleConv(\n",
       "        (SingleConv1): SingleConv(\n",
       "          (groupnorm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (SingleConv2): SingleConv(\n",
       "          (groupnorm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): Encoder(\n",
       "      (pooling): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (basic_module): DoubleConv(\n",
       "        (SingleConv1): SingleConv(\n",
       "          (groupnorm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (SingleConv2): SingleConv(\n",
       "          (groupnorm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): Encoder(\n",
       "      (pooling): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (basic_module): DoubleConv(\n",
       "        (SingleConv1): SingleConv(\n",
       "          (groupnorm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (SingleConv2): SingleConv(\n",
       "          (groupnorm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoders): ModuleList(\n",
       "    (0): Decoder(\n",
       "      (upsampling): InterpolateUpsampling()\n",
       "      (basic_module): DoubleConv(\n",
       "        (SingleConv1): SingleConv(\n",
       "          (groupnorm): GroupNorm(8, 768, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(768, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (SingleConv2): SingleConv(\n",
       "          (groupnorm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Decoder(\n",
       "      (upsampling): InterpolateUpsampling()\n",
       "      (basic_module): DoubleConv(\n",
       "        (SingleConv1): SingleConv(\n",
       "          (groupnorm): GroupNorm(8, 384, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(384, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (SingleConv2): SingleConv(\n",
       "          (groupnorm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): Decoder(\n",
       "      (upsampling): InterpolateUpsampling()\n",
       "      (basic_module): DoubleConv(\n",
       "        (SingleConv1): SingleConv(\n",
       "          (groupnorm): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(192, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "        (SingleConv2): SingleConv(\n",
       "          (groupnorm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (ReLU): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (final_conv): Conv3d(64, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = model.UNet3D(in_channels=2, out_channels=1, num_groups=8, is_segmentation=False)\n",
    "best_model_weights = '../3D_models/3D_model_weights/lr5e-4_wd1e-3_do04/model_lr0.0005_wd0.001_do0.4_epoch30.pth'\n",
    "\n",
    "checkpoint = torch.load(best_model_weights, map_location=device, weights_only=True)\n",
    "\n",
    "# Only load the model state dict from the checkpoint\n",
    "best_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Set model in evaluation mode\n",
    "best_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepearing data from 3D model to 4D model\n",
    "\n",
    "Determining indices for data splitting into training, validation and test data. Using the same participants as used in 3D preprocessing. The k-space data is already divided into appropriate folders, but the indices will be used for splitting EPI data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test patient index: 1\n",
      "Val patient index: 0\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "TEST_PARTICIPANT = random.randint(0,9)\n",
    "VAL_PARTICIPANT = random.randint(0,8)\n",
    "print(f'Test patient index: {TEST_PARTICIPANT}')\n",
    "print(f'Val patient index: {VAL_PARTICIPANT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadData(Dataset):\n",
    "    \"\"\" \n",
    "    Custom Dataset for loading preprocessed k-space and image pairs.\n",
    "\n",
    "    This dataset assumes that each data point has been saved as a pair of '.pt' files:\n",
    "    - 'kspace{idx}.pt' in 'kspace_folder'\n",
    "    - 'img{idx}.pt' in 'image_folder'\n",
    "\n",
    "    Indexing follows:\n",
    "    - Training set: indexes 0 to 363\n",
    "    - Validation/Test set: indexes 0 to 51\n",
    "\n",
    "    Parameters:\n",
    "    - kspace_folder: Path to directory containing k-space files.\n",
    "    - image_folder: Path to directory containing image files.\n",
    "    - datatype: Type of dataset: either 'train', 'val', or 'test'.\n",
    "    \"\"\"\n",
    "    def __init__(self, kspace_folder, image_folder, datatype):\n",
    "        self.kspace_folder = kspace_folder\n",
    "        self.image_folder = image_folder\n",
    "        self.datatype = datatype\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        if self.datatype == 'train':\n",
    "            return 364\n",
    "        else:\n",
    "            return 52\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\" \n",
    "        Loads and returns a single sample (k-space, image) pair.\n",
    "        \"\"\"\n",
    "        image_path = os.path.join(self.image_folder, f'img{idx}.pt')\n",
    "        kspace_path = os.path.join(self.kspace_folder, f'kspace{idx}.pt')\n",
    "        image = torch.load(image_path)\n",
    "        kspace = torch.load(kspace_path)\n",
    "        return kspace, image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining paths for k-space data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_path = './preprocessed_img_train'\n",
    "train_kspace_path = './preprocessed_kspace_train'\n",
    "\n",
    "val_img_path = './preprocessed_img_val'\n",
    "val_kspace_path = './preprocessed_kspace_val'\n",
    "\n",
    "test_img_path = './preprocessed_img_test'\n",
    "test_kspace_path = './preprocessed_kspace_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image_space(image_data):\n",
    "    \"\"\" \n",
    "    Resize images. \n",
    "    Original shape: [1, 1, 128, 128, 128]\n",
    "    Desired shape: [1, 1, 64, 64, 64]\n",
    "\n",
    "    Parameters:\n",
    "    - image_data: Image to be resized\n",
    "\n",
    "    Returns:\n",
    "    - resized_img: Resized image.\n",
    "    \"\"\"\n",
    "    zoom_factors = (1,1, 64/128, 64/128, 64/128)\n",
    "\n",
    "    resized_img = zoom(image_data, zoom_factors, order=1)\n",
    "    return resized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_ls(no_participants, data_type, save_file_path):\n",
    "    \"\"\"\n",
    "    Acquiring predictions from the best performing 3D-UNet and assembling into 4D volume.\n",
    "    Parameters:\n",
    "    - no_participants: Number of participants in the dataset (7 for train, 1 for validation, 1 for test)\n",
    "    - data_type: Determining the type of dataset. Will save the data into the correct folder. (Train, validation, test)\n",
    "    - save_file_path: Path to save the processed data.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    best_model.eval()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    best_model.to(device=device)\n",
    "\n",
    "    # Specifying data type for correct path\n",
    "    if data_type == 'train':\n",
    "        file_path = train_kspace_path\n",
    "    elif data_type == 'val':\n",
    "        file_path = val_kspace_path\n",
    "    elif data_type == 'test':\n",
    "        file_path = test_kspace_path\n",
    "    else:\n",
    "        print('Select data type')\n",
    " \n",
    "\n",
    "    for i in range(0,no_participants):\n",
    "        patient_image = []\n",
    "        for j in range(0,52):\n",
    "            # Data is stored in numbers from 0 to 363 for training data. Second loop is to ensure \n",
    "            # each chunk of data only consists of 52 data points before moving on to next participant\n",
    "            # when looping through training data\n",
    "\n",
    "            # Printing participate number, time slice number and index number to ensure correct preprocessing\n",
    "            print(f'Participant no: {i}, time slice no: {j}, index: {i*52+j}') \n",
    "            index = i*52+j\n",
    "\n",
    "            # Loading data from the correct path\n",
    "            kspace_path = os.path.join(file_path, f'kspace{index}.pt')\n",
    "            current_kspace = torch.load(kspace_path)\n",
    "\n",
    "            # Unsqueezing to add batch dimension\n",
    "            current_kspace = current_kspace.unsqueeze(0)\n",
    "            current_kspace = current_kspace.to(device=device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # Getting predictions from the 3D-UNet\n",
    "                pred = best_model(current_kspace)\n",
    "\n",
    "                # Removing batch dimension\n",
    "                pred = pred.squeeze(1).cpu()\n",
    "        \n",
    "            patient_image.append(pred)\n",
    "\n",
    "        # Assembling each 3D data point into a 4D volume\n",
    "        recon_img = np.array(patient_image)\n",
    "        recon_img = torch.Tensor(recon_img)\n",
    "        \n",
    "        recon_img = recon_img.permute(1,0,2,3,4)\n",
    "\n",
    "        # Resizing predictions to match the 4D-UNet requirements\n",
    "        recon_img_resized = resize_image_space(recon_img)\n",
    "\n",
    "        current_filename = os.path.join(save_file_path, f'preprocessed{i}.pt')\n",
    "\n",
    "        # Saving the processed files with the correct file name\n",
    "        torch.save(recon_img_resized, current_filename)\n",
    "        print(f'Finished processing participant {i}. Shape: {recon_img_resized.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant no: 0, time slice no: 0, index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Caroline\\AppData\\Local\\Temp\\ipykernel_21952\\2086750614.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  current_kspace = torch.load(kspace_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant no: 0, time slice no: 1, index: 1\n",
      "Participant no: 0, time slice no: 2, index: 2\n",
      "Participant no: 0, time slice no: 3, index: 3\n",
      "Participant no: 0, time slice no: 4, index: 4\n",
      "Participant no: 0, time slice no: 5, index: 5\n",
      "Participant no: 0, time slice no: 6, index: 6\n",
      "Participant no: 0, time slice no: 7, index: 7\n",
      "Participant no: 0, time slice no: 8, index: 8\n",
      "Participant no: 0, time slice no: 9, index: 9\n",
      "Participant no: 0, time slice no: 10, index: 10\n",
      "Participant no: 0, time slice no: 11, index: 11\n",
      "Participant no: 0, time slice no: 12, index: 12\n",
      "Participant no: 0, time slice no: 13, index: 13\n",
      "Participant no: 0, time slice no: 14, index: 14\n",
      "Participant no: 0, time slice no: 15, index: 15\n",
      "Participant no: 0, time slice no: 16, index: 16\n",
      "Participant no: 0, time slice no: 17, index: 17\n",
      "Participant no: 0, time slice no: 18, index: 18\n",
      "Participant no: 0, time slice no: 19, index: 19\n",
      "Participant no: 0, time slice no: 20, index: 20\n",
      "Participant no: 0, time slice no: 21, index: 21\n",
      "Participant no: 0, time slice no: 22, index: 22\n",
      "Participant no: 0, time slice no: 23, index: 23\n",
      "Participant no: 0, time slice no: 24, index: 24\n",
      "Participant no: 0, time slice no: 25, index: 25\n",
      "Participant no: 0, time slice no: 26, index: 26\n",
      "Participant no: 0, time slice no: 27, index: 27\n",
      "Participant no: 0, time slice no: 28, index: 28\n",
      "Participant no: 0, time slice no: 29, index: 29\n",
      "Participant no: 0, time slice no: 30, index: 30\n",
      "Participant no: 0, time slice no: 31, index: 31\n",
      "Participant no: 0, time slice no: 32, index: 32\n",
      "Participant no: 0, time slice no: 33, index: 33\n",
      "Participant no: 0, time slice no: 34, index: 34\n",
      "Participant no: 0, time slice no: 35, index: 35\n",
      "Participant no: 0, time slice no: 36, index: 36\n",
      "Participant no: 0, time slice no: 37, index: 37\n",
      "Participant no: 0, time slice no: 38, index: 38\n",
      "Participant no: 0, time slice no: 39, index: 39\n",
      "Participant no: 0, time slice no: 40, index: 40\n",
      "Participant no: 0, time slice no: 41, index: 41\n",
      "Participant no: 0, time slice no: 42, index: 42\n",
      "Participant no: 0, time slice no: 43, index: 43\n",
      "Participant no: 0, time slice no: 44, index: 44\n",
      "Participant no: 0, time slice no: 45, index: 45\n",
      "Participant no: 0, time slice no: 46, index: 46\n",
      "Participant no: 0, time slice no: 47, index: 47\n",
      "Participant no: 0, time slice no: 48, index: 48\n",
      "Participant no: 0, time slice no: 49, index: 49\n",
      "Participant no: 0, time slice no: 50, index: 50\n",
      "Participant no: 0, time slice no: 51, index: 51\n",
      "Finished processing participant 0. Shape: (1, 52, 64, 64, 64)\n",
      "Participant no: 1, time slice no: 0, index: 52\n",
      "Participant no: 1, time slice no: 1, index: 53\n",
      "Participant no: 1, time slice no: 2, index: 54\n",
      "Participant no: 1, time slice no: 3, index: 55\n",
      "Participant no: 1, time slice no: 4, index: 56\n",
      "Participant no: 1, time slice no: 5, index: 57\n",
      "Participant no: 1, time slice no: 6, index: 58\n",
      "Participant no: 1, time slice no: 7, index: 59\n",
      "Participant no: 1, time slice no: 8, index: 60\n",
      "Participant no: 1, time slice no: 9, index: 61\n",
      "Participant no: 1, time slice no: 10, index: 62\n",
      "Participant no: 1, time slice no: 11, index: 63\n",
      "Participant no: 1, time slice no: 12, index: 64\n",
      "Participant no: 1, time slice no: 13, index: 65\n",
      "Participant no: 1, time slice no: 14, index: 66\n",
      "Participant no: 1, time slice no: 15, index: 67\n",
      "Participant no: 1, time slice no: 16, index: 68\n",
      "Participant no: 1, time slice no: 17, index: 69\n",
      "Participant no: 1, time slice no: 18, index: 70\n",
      "Participant no: 1, time slice no: 19, index: 71\n",
      "Participant no: 1, time slice no: 20, index: 72\n",
      "Participant no: 1, time slice no: 21, index: 73\n",
      "Participant no: 1, time slice no: 22, index: 74\n",
      "Participant no: 1, time slice no: 23, index: 75\n",
      "Participant no: 1, time slice no: 24, index: 76\n",
      "Participant no: 1, time slice no: 25, index: 77\n",
      "Participant no: 1, time slice no: 26, index: 78\n",
      "Participant no: 1, time slice no: 27, index: 79\n",
      "Participant no: 1, time slice no: 28, index: 80\n",
      "Participant no: 1, time slice no: 29, index: 81\n",
      "Participant no: 1, time slice no: 30, index: 82\n",
      "Participant no: 1, time slice no: 31, index: 83\n",
      "Participant no: 1, time slice no: 32, index: 84\n",
      "Participant no: 1, time slice no: 33, index: 85\n",
      "Participant no: 1, time slice no: 34, index: 86\n",
      "Participant no: 1, time slice no: 35, index: 87\n",
      "Participant no: 1, time slice no: 36, index: 88\n",
      "Participant no: 1, time slice no: 37, index: 89\n",
      "Participant no: 1, time slice no: 38, index: 90\n",
      "Participant no: 1, time slice no: 39, index: 91\n",
      "Participant no: 1, time slice no: 40, index: 92\n",
      "Participant no: 1, time slice no: 41, index: 93\n",
      "Participant no: 1, time slice no: 42, index: 94\n",
      "Participant no: 1, time slice no: 43, index: 95\n",
      "Participant no: 1, time slice no: 44, index: 96\n",
      "Participant no: 1, time slice no: 45, index: 97\n",
      "Participant no: 1, time slice no: 46, index: 98\n",
      "Participant no: 1, time slice no: 47, index: 99\n",
      "Participant no: 1, time slice no: 48, index: 100\n",
      "Participant no: 1, time slice no: 49, index: 101\n",
      "Participant no: 1, time slice no: 50, index: 102\n",
      "Participant no: 1, time slice no: 51, index: 103\n",
      "Finished processing participant 1. Shape: (1, 52, 64, 64, 64)\n",
      "Participant no: 2, time slice no: 0, index: 104\n",
      "Participant no: 2, time slice no: 1, index: 105\n",
      "Participant no: 2, time slice no: 2, index: 106\n",
      "Participant no: 2, time slice no: 3, index: 107\n",
      "Participant no: 2, time slice no: 4, index: 108\n",
      "Participant no: 2, time slice no: 5, index: 109\n",
      "Participant no: 2, time slice no: 6, index: 110\n",
      "Participant no: 2, time slice no: 7, index: 111\n",
      "Participant no: 2, time slice no: 8, index: 112\n",
      "Participant no: 2, time slice no: 9, index: 113\n",
      "Participant no: 2, time slice no: 10, index: 114\n",
      "Participant no: 2, time slice no: 11, index: 115\n",
      "Participant no: 2, time slice no: 12, index: 116\n",
      "Participant no: 2, time slice no: 13, index: 117\n",
      "Participant no: 2, time slice no: 14, index: 118\n",
      "Participant no: 2, time slice no: 15, index: 119\n",
      "Participant no: 2, time slice no: 16, index: 120\n",
      "Participant no: 2, time slice no: 17, index: 121\n",
      "Participant no: 2, time slice no: 18, index: 122\n",
      "Participant no: 2, time slice no: 19, index: 123\n",
      "Participant no: 2, time slice no: 20, index: 124\n",
      "Participant no: 2, time slice no: 21, index: 125\n",
      "Participant no: 2, time slice no: 22, index: 126\n",
      "Participant no: 2, time slice no: 23, index: 127\n",
      "Participant no: 2, time slice no: 24, index: 128\n",
      "Participant no: 2, time slice no: 25, index: 129\n",
      "Participant no: 2, time slice no: 26, index: 130\n",
      "Participant no: 2, time slice no: 27, index: 131\n",
      "Participant no: 2, time slice no: 28, index: 132\n",
      "Participant no: 2, time slice no: 29, index: 133\n",
      "Participant no: 2, time slice no: 30, index: 134\n",
      "Participant no: 2, time slice no: 31, index: 135\n",
      "Participant no: 2, time slice no: 32, index: 136\n",
      "Participant no: 2, time slice no: 33, index: 137\n",
      "Participant no: 2, time slice no: 34, index: 138\n",
      "Participant no: 2, time slice no: 35, index: 139\n",
      "Participant no: 2, time slice no: 36, index: 140\n",
      "Participant no: 2, time slice no: 37, index: 141\n",
      "Participant no: 2, time slice no: 38, index: 142\n",
      "Participant no: 2, time slice no: 39, index: 143\n",
      "Participant no: 2, time slice no: 40, index: 144\n",
      "Participant no: 2, time slice no: 41, index: 145\n",
      "Participant no: 2, time slice no: 42, index: 146\n",
      "Participant no: 2, time slice no: 43, index: 147\n",
      "Participant no: 2, time slice no: 44, index: 148\n",
      "Participant no: 2, time slice no: 45, index: 149\n",
      "Participant no: 2, time slice no: 46, index: 150\n",
      "Participant no: 2, time slice no: 47, index: 151\n",
      "Participant no: 2, time slice no: 48, index: 152\n",
      "Participant no: 2, time slice no: 49, index: 153\n",
      "Participant no: 2, time slice no: 50, index: 154\n",
      "Participant no: 2, time slice no: 51, index: 155\n",
      "Finished processing participant 2. Shape: (1, 52, 64, 64, 64)\n",
      "Participant no: 3, time slice no: 0, index: 156\n",
      "Participant no: 3, time slice no: 1, index: 157\n",
      "Participant no: 3, time slice no: 2, index: 158\n",
      "Participant no: 3, time slice no: 3, index: 159\n",
      "Participant no: 3, time slice no: 4, index: 160\n",
      "Participant no: 3, time slice no: 5, index: 161\n",
      "Participant no: 3, time slice no: 6, index: 162\n",
      "Participant no: 3, time slice no: 7, index: 163\n",
      "Participant no: 3, time slice no: 8, index: 164\n",
      "Participant no: 3, time slice no: 9, index: 165\n",
      "Participant no: 3, time slice no: 10, index: 166\n",
      "Participant no: 3, time slice no: 11, index: 167\n",
      "Participant no: 3, time slice no: 12, index: 168\n",
      "Participant no: 3, time slice no: 13, index: 169\n",
      "Participant no: 3, time slice no: 14, index: 170\n",
      "Participant no: 3, time slice no: 15, index: 171\n",
      "Participant no: 3, time slice no: 16, index: 172\n",
      "Participant no: 3, time slice no: 17, index: 173\n",
      "Participant no: 3, time slice no: 18, index: 174\n",
      "Participant no: 3, time slice no: 19, index: 175\n",
      "Participant no: 3, time slice no: 20, index: 176\n",
      "Participant no: 3, time slice no: 21, index: 177\n",
      "Participant no: 3, time slice no: 22, index: 178\n",
      "Participant no: 3, time slice no: 23, index: 179\n",
      "Participant no: 3, time slice no: 24, index: 180\n",
      "Participant no: 3, time slice no: 25, index: 181\n",
      "Participant no: 3, time slice no: 26, index: 182\n",
      "Participant no: 3, time slice no: 27, index: 183\n",
      "Participant no: 3, time slice no: 28, index: 184\n",
      "Participant no: 3, time slice no: 29, index: 185\n",
      "Participant no: 3, time slice no: 30, index: 186\n",
      "Participant no: 3, time slice no: 31, index: 187\n",
      "Participant no: 3, time slice no: 32, index: 188\n",
      "Participant no: 3, time slice no: 33, index: 189\n",
      "Participant no: 3, time slice no: 34, index: 190\n",
      "Participant no: 3, time slice no: 35, index: 191\n",
      "Participant no: 3, time slice no: 36, index: 192\n",
      "Participant no: 3, time slice no: 37, index: 193\n",
      "Participant no: 3, time slice no: 38, index: 194\n",
      "Participant no: 3, time slice no: 39, index: 195\n",
      "Participant no: 3, time slice no: 40, index: 196\n",
      "Participant no: 3, time slice no: 41, index: 197\n",
      "Participant no: 3, time slice no: 42, index: 198\n",
      "Participant no: 3, time slice no: 43, index: 199\n",
      "Participant no: 3, time slice no: 44, index: 200\n",
      "Participant no: 3, time slice no: 45, index: 201\n",
      "Participant no: 3, time slice no: 46, index: 202\n",
      "Participant no: 3, time slice no: 47, index: 203\n",
      "Participant no: 3, time slice no: 48, index: 204\n",
      "Participant no: 3, time slice no: 49, index: 205\n",
      "Participant no: 3, time slice no: 50, index: 206\n",
      "Participant no: 3, time slice no: 51, index: 207\n",
      "Finished processing participant 3. Shape: (1, 52, 64, 64, 64)\n",
      "Participant no: 4, time slice no: 0, index: 208\n",
      "Participant no: 4, time slice no: 1, index: 209\n",
      "Participant no: 4, time slice no: 2, index: 210\n",
      "Participant no: 4, time slice no: 3, index: 211\n",
      "Participant no: 4, time slice no: 4, index: 212\n",
      "Participant no: 4, time slice no: 5, index: 213\n",
      "Participant no: 4, time slice no: 6, index: 214\n",
      "Participant no: 4, time slice no: 7, index: 215\n",
      "Participant no: 4, time slice no: 8, index: 216\n",
      "Participant no: 4, time slice no: 9, index: 217\n",
      "Participant no: 4, time slice no: 10, index: 218\n",
      "Participant no: 4, time slice no: 11, index: 219\n",
      "Participant no: 4, time slice no: 12, index: 220\n",
      "Participant no: 4, time slice no: 13, index: 221\n",
      "Participant no: 4, time slice no: 14, index: 222\n",
      "Participant no: 4, time slice no: 15, index: 223\n",
      "Participant no: 4, time slice no: 16, index: 224\n",
      "Participant no: 4, time slice no: 17, index: 225\n",
      "Participant no: 4, time slice no: 18, index: 226\n",
      "Participant no: 4, time slice no: 19, index: 227\n",
      "Participant no: 4, time slice no: 20, index: 228\n",
      "Participant no: 4, time slice no: 21, index: 229\n",
      "Participant no: 4, time slice no: 22, index: 230\n",
      "Participant no: 4, time slice no: 23, index: 231\n",
      "Participant no: 4, time slice no: 24, index: 232\n",
      "Participant no: 4, time slice no: 25, index: 233\n",
      "Participant no: 4, time slice no: 26, index: 234\n",
      "Participant no: 4, time slice no: 27, index: 235\n",
      "Participant no: 4, time slice no: 28, index: 236\n",
      "Participant no: 4, time slice no: 29, index: 237\n",
      "Participant no: 4, time slice no: 30, index: 238\n",
      "Participant no: 4, time slice no: 31, index: 239\n",
      "Participant no: 4, time slice no: 32, index: 240\n",
      "Participant no: 4, time slice no: 33, index: 241\n",
      "Participant no: 4, time slice no: 34, index: 242\n",
      "Participant no: 4, time slice no: 35, index: 243\n",
      "Participant no: 4, time slice no: 36, index: 244\n",
      "Participant no: 4, time slice no: 37, index: 245\n",
      "Participant no: 4, time slice no: 38, index: 246\n",
      "Participant no: 4, time slice no: 39, index: 247\n",
      "Participant no: 4, time slice no: 40, index: 248\n",
      "Participant no: 4, time slice no: 41, index: 249\n",
      "Participant no: 4, time slice no: 42, index: 250\n",
      "Participant no: 4, time slice no: 43, index: 251\n",
      "Participant no: 4, time slice no: 44, index: 252\n",
      "Participant no: 4, time slice no: 45, index: 253\n",
      "Participant no: 4, time slice no: 46, index: 254\n",
      "Participant no: 4, time slice no: 47, index: 255\n",
      "Participant no: 4, time slice no: 48, index: 256\n",
      "Participant no: 4, time slice no: 49, index: 257\n",
      "Participant no: 4, time slice no: 50, index: 258\n",
      "Participant no: 4, time slice no: 51, index: 259\n",
      "Finished processing participant 4. Shape: (1, 52, 64, 64, 64)\n",
      "Participant no: 5, time slice no: 0, index: 260\n",
      "Participant no: 5, time slice no: 1, index: 261\n",
      "Participant no: 5, time slice no: 2, index: 262\n",
      "Participant no: 5, time slice no: 3, index: 263\n",
      "Participant no: 5, time slice no: 4, index: 264\n",
      "Participant no: 5, time slice no: 5, index: 265\n",
      "Participant no: 5, time slice no: 6, index: 266\n",
      "Participant no: 5, time slice no: 7, index: 267\n",
      "Participant no: 5, time slice no: 8, index: 268\n",
      "Participant no: 5, time slice no: 9, index: 269\n",
      "Participant no: 5, time slice no: 10, index: 270\n",
      "Participant no: 5, time slice no: 11, index: 271\n",
      "Participant no: 5, time slice no: 12, index: 272\n",
      "Participant no: 5, time slice no: 13, index: 273\n",
      "Participant no: 5, time slice no: 14, index: 274\n",
      "Participant no: 5, time slice no: 15, index: 275\n",
      "Participant no: 5, time slice no: 16, index: 276\n",
      "Participant no: 5, time slice no: 17, index: 277\n",
      "Participant no: 5, time slice no: 18, index: 278\n",
      "Participant no: 5, time slice no: 19, index: 279\n",
      "Participant no: 5, time slice no: 20, index: 280\n",
      "Participant no: 5, time slice no: 21, index: 281\n",
      "Participant no: 5, time slice no: 22, index: 282\n",
      "Participant no: 5, time slice no: 23, index: 283\n",
      "Participant no: 5, time slice no: 24, index: 284\n",
      "Participant no: 5, time slice no: 25, index: 285\n",
      "Participant no: 5, time slice no: 26, index: 286\n",
      "Participant no: 5, time slice no: 27, index: 287\n",
      "Participant no: 5, time slice no: 28, index: 288\n",
      "Participant no: 5, time slice no: 29, index: 289\n",
      "Participant no: 5, time slice no: 30, index: 290\n",
      "Participant no: 5, time slice no: 31, index: 291\n",
      "Participant no: 5, time slice no: 32, index: 292\n",
      "Participant no: 5, time slice no: 33, index: 293\n",
      "Participant no: 5, time slice no: 34, index: 294\n",
      "Participant no: 5, time slice no: 35, index: 295\n",
      "Participant no: 5, time slice no: 36, index: 296\n",
      "Participant no: 5, time slice no: 37, index: 297\n",
      "Participant no: 5, time slice no: 38, index: 298\n",
      "Participant no: 5, time slice no: 39, index: 299\n",
      "Participant no: 5, time slice no: 40, index: 300\n",
      "Participant no: 5, time slice no: 41, index: 301\n",
      "Participant no: 5, time slice no: 42, index: 302\n",
      "Participant no: 5, time slice no: 43, index: 303\n",
      "Participant no: 5, time slice no: 44, index: 304\n",
      "Participant no: 5, time slice no: 45, index: 305\n",
      "Participant no: 5, time slice no: 46, index: 306\n",
      "Participant no: 5, time slice no: 47, index: 307\n",
      "Participant no: 5, time slice no: 48, index: 308\n",
      "Participant no: 5, time slice no: 49, index: 309\n",
      "Participant no: 5, time slice no: 50, index: 310\n",
      "Participant no: 5, time slice no: 51, index: 311\n",
      "Finished processing participant 5. Shape: (1, 52, 64, 64, 64)\n",
      "Participant no: 6, time slice no: 0, index: 312\n",
      "Participant no: 6, time slice no: 1, index: 313\n",
      "Participant no: 6, time slice no: 2, index: 314\n",
      "Participant no: 6, time slice no: 3, index: 315\n",
      "Participant no: 6, time slice no: 4, index: 316\n",
      "Participant no: 6, time slice no: 5, index: 317\n",
      "Participant no: 6, time slice no: 6, index: 318\n",
      "Participant no: 6, time slice no: 7, index: 319\n",
      "Participant no: 6, time slice no: 8, index: 320\n",
      "Participant no: 6, time slice no: 9, index: 321\n",
      "Participant no: 6, time slice no: 10, index: 322\n",
      "Participant no: 6, time slice no: 11, index: 323\n",
      "Participant no: 6, time slice no: 12, index: 324\n",
      "Participant no: 6, time slice no: 13, index: 325\n",
      "Participant no: 6, time slice no: 14, index: 326\n",
      "Participant no: 6, time slice no: 15, index: 327\n",
      "Participant no: 6, time slice no: 16, index: 328\n",
      "Participant no: 6, time slice no: 17, index: 329\n",
      "Participant no: 6, time slice no: 18, index: 330\n",
      "Participant no: 6, time slice no: 19, index: 331\n",
      "Participant no: 6, time slice no: 20, index: 332\n",
      "Participant no: 6, time slice no: 21, index: 333\n",
      "Participant no: 6, time slice no: 22, index: 334\n",
      "Participant no: 6, time slice no: 23, index: 335\n",
      "Participant no: 6, time slice no: 24, index: 336\n",
      "Participant no: 6, time slice no: 25, index: 337\n",
      "Participant no: 6, time slice no: 26, index: 338\n",
      "Participant no: 6, time slice no: 27, index: 339\n",
      "Participant no: 6, time slice no: 28, index: 340\n",
      "Participant no: 6, time slice no: 29, index: 341\n",
      "Participant no: 6, time slice no: 30, index: 342\n",
      "Participant no: 6, time slice no: 31, index: 343\n",
      "Participant no: 6, time slice no: 32, index: 344\n",
      "Participant no: 6, time slice no: 33, index: 345\n",
      "Participant no: 6, time slice no: 34, index: 346\n",
      "Participant no: 6, time slice no: 35, index: 347\n",
      "Participant no: 6, time slice no: 36, index: 348\n",
      "Participant no: 6, time slice no: 37, index: 349\n",
      "Participant no: 6, time slice no: 38, index: 350\n",
      "Participant no: 6, time slice no: 39, index: 351\n",
      "Participant no: 6, time slice no: 40, index: 352\n",
      "Participant no: 6, time slice no: 41, index: 353\n",
      "Participant no: 6, time slice no: 42, index: 354\n",
      "Participant no: 6, time slice no: 43, index: 355\n",
      "Participant no: 6, time slice no: 44, index: 356\n",
      "Participant no: 6, time slice no: 45, index: 357\n",
      "Participant no: 6, time slice no: 46, index: 358\n",
      "Participant no: 6, time slice no: 47, index: 359\n",
      "Participant no: 6, time slice no: 48, index: 360\n",
      "Participant no: 6, time slice no: 49, index: 361\n",
      "Participant no: 6, time slice no: 50, index: 362\n",
      "Participant no: 6, time slice no: 51, index: 363\n",
      "Finished processing participant 6. Shape: (1, 52, 64, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "train_filename = '../preprocessed_4d/ls_train'\n",
    "preprocess_ls(no_patients=7, data_type='train', save_file_path=train_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant no: 0, time slice no: 0, index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Caroline\\AppData\\Local\\Temp\\ipykernel_21952\\2086750614.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  current_kspace = torch.load(kspace_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant no: 0, time slice no: 1, index: 1\n",
      "Participant no: 0, time slice no: 2, index: 2\n",
      "Participant no: 0, time slice no: 3, index: 3\n",
      "Participant no: 0, time slice no: 4, index: 4\n",
      "Participant no: 0, time slice no: 5, index: 5\n",
      "Participant no: 0, time slice no: 6, index: 6\n",
      "Participant no: 0, time slice no: 7, index: 7\n",
      "Participant no: 0, time slice no: 8, index: 8\n",
      "Participant no: 0, time slice no: 9, index: 9\n",
      "Participant no: 0, time slice no: 10, index: 10\n",
      "Participant no: 0, time slice no: 11, index: 11\n",
      "Participant no: 0, time slice no: 12, index: 12\n",
      "Participant no: 0, time slice no: 13, index: 13\n",
      "Participant no: 0, time slice no: 14, index: 14\n",
      "Participant no: 0, time slice no: 15, index: 15\n",
      "Participant no: 0, time slice no: 16, index: 16\n",
      "Participant no: 0, time slice no: 17, index: 17\n",
      "Participant no: 0, time slice no: 18, index: 18\n",
      "Participant no: 0, time slice no: 19, index: 19\n",
      "Participant no: 0, time slice no: 20, index: 20\n",
      "Participant no: 0, time slice no: 21, index: 21\n",
      "Participant no: 0, time slice no: 22, index: 22\n",
      "Participant no: 0, time slice no: 23, index: 23\n",
      "Participant no: 0, time slice no: 24, index: 24\n",
      "Participant no: 0, time slice no: 25, index: 25\n",
      "Participant no: 0, time slice no: 26, index: 26\n",
      "Participant no: 0, time slice no: 27, index: 27\n",
      "Participant no: 0, time slice no: 28, index: 28\n",
      "Participant no: 0, time slice no: 29, index: 29\n",
      "Participant no: 0, time slice no: 30, index: 30\n",
      "Participant no: 0, time slice no: 31, index: 31\n",
      "Participant no: 0, time slice no: 32, index: 32\n",
      "Participant no: 0, time slice no: 33, index: 33\n",
      "Participant no: 0, time slice no: 34, index: 34\n",
      "Participant no: 0, time slice no: 35, index: 35\n",
      "Participant no: 0, time slice no: 36, index: 36\n",
      "Participant no: 0, time slice no: 37, index: 37\n",
      "Participant no: 0, time slice no: 38, index: 38\n",
      "Participant no: 0, time slice no: 39, index: 39\n",
      "Participant no: 0, time slice no: 40, index: 40\n",
      "Participant no: 0, time slice no: 41, index: 41\n",
      "Participant no: 0, time slice no: 42, index: 42\n",
      "Participant no: 0, time slice no: 43, index: 43\n",
      "Participant no: 0, time slice no: 44, index: 44\n",
      "Participant no: 0, time slice no: 45, index: 45\n",
      "Participant no: 0, time slice no: 46, index: 46\n",
      "Participant no: 0, time slice no: 47, index: 47\n",
      "Participant no: 0, time slice no: 48, index: 48\n",
      "Participant no: 0, time slice no: 49, index: 49\n",
      "Participant no: 0, time slice no: 50, index: 50\n",
      "Participant no: 0, time slice no: 51, index: 51\n",
      "Finished processing participant 0. Shape: (1, 52, 64, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "val_filename = '../preprocessed_4d/ls_val'\n",
    "preprocess_ls(no_patients=1, data_type='val', save_file_path=val_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant no: 0, time slice no: 0, index: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Caroline\\AppData\\Local\\Temp\\ipykernel_21952\\2086750614.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  current_kspace = torch.load(kspace_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant no: 0, time slice no: 1, index: 1\n",
      "Participant no: 0, time slice no: 2, index: 2\n",
      "Participant no: 0, time slice no: 3, index: 3\n",
      "Participant no: 0, time slice no: 4, index: 4\n",
      "Participant no: 0, time slice no: 5, index: 5\n",
      "Participant no: 0, time slice no: 6, index: 6\n",
      "Participant no: 0, time slice no: 7, index: 7\n",
      "Participant no: 0, time slice no: 8, index: 8\n",
      "Participant no: 0, time slice no: 9, index: 9\n",
      "Participant no: 0, time slice no: 10, index: 10\n",
      "Participant no: 0, time slice no: 11, index: 11\n",
      "Participant no: 0, time slice no: 12, index: 12\n",
      "Participant no: 0, time slice no: 13, index: 13\n",
      "Participant no: 0, time slice no: 14, index: 14\n",
      "Participant no: 0, time slice no: 15, index: 15\n",
      "Participant no: 0, time slice no: 16, index: 16\n",
      "Participant no: 0, time slice no: 17, index: 17\n",
      "Participant no: 0, time slice no: 18, index: 18\n",
      "Participant no: 0, time slice no: 19, index: 19\n",
      "Participant no: 0, time slice no: 20, index: 20\n",
      "Participant no: 0, time slice no: 21, index: 21\n",
      "Participant no: 0, time slice no: 22, index: 22\n",
      "Participant no: 0, time slice no: 23, index: 23\n",
      "Participant no: 0, time slice no: 24, index: 24\n",
      "Participant no: 0, time slice no: 25, index: 25\n",
      "Participant no: 0, time slice no: 26, index: 26\n",
      "Participant no: 0, time slice no: 27, index: 27\n",
      "Participant no: 0, time slice no: 28, index: 28\n",
      "Participant no: 0, time slice no: 29, index: 29\n",
      "Participant no: 0, time slice no: 30, index: 30\n",
      "Participant no: 0, time slice no: 31, index: 31\n",
      "Participant no: 0, time slice no: 32, index: 32\n",
      "Participant no: 0, time slice no: 33, index: 33\n",
      "Participant no: 0, time slice no: 34, index: 34\n",
      "Participant no: 0, time slice no: 35, index: 35\n",
      "Participant no: 0, time slice no: 36, index: 36\n",
      "Participant no: 0, time slice no: 37, index: 37\n",
      "Participant no: 0, time slice no: 38, index: 38\n",
      "Participant no: 0, time slice no: 39, index: 39\n",
      "Participant no: 0, time slice no: 40, index: 40\n",
      "Participant no: 0, time slice no: 41, index: 41\n",
      "Participant no: 0, time slice no: 42, index: 42\n",
      "Participant no: 0, time slice no: 43, index: 43\n",
      "Participant no: 0, time slice no: 44, index: 44\n",
      "Participant no: 0, time slice no: 45, index: 45\n",
      "Participant no: 0, time slice no: 46, index: 46\n",
      "Participant no: 0, time slice no: 47, index: 47\n",
      "Participant no: 0, time slice no: 48, index: 48\n",
      "Participant no: 0, time slice no: 49, index: 49\n",
      "Participant no: 0, time slice no: 50, index: 50\n",
      "Participant no: 0, time slice no: 51, index: 51\n",
      "Finished processing participant 0. Shape: (1, 52, 64, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "test_filename = '../preprocessed_4d/ls_test'\n",
    "preprocess_ls(no_patients=1, data_type='test', save_file_path=test_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading EPI data\n",
    "\n",
    "The EPI data gets preprocessed to match the data type of the reconstruced LS volumes. That includes temporal subsampling and normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epi_path = \"../../data/KSPACE/epi\"\n",
    "epi_files = [f for f in os.listdir(epi_path) if f.endswith(\".nii\")] \n",
    "\n",
    "epi_images = [] \n",
    "\n",
    "for i, filename in enumerate(epi_files, start=1):\n",
    "    file_path = os.path.join(epi_path, filename)\n",
    "    epi_images.append(nib.load(file_path).get_fdata())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsampling the correct time points according to the LS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epi_images_sliced = [image[:,:,:,90:142] for image in epi_images] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing into training-, validation-, and test-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epi_images_sliced_test = [epi_images_sliced[TEST_PARTICIPANT]]\n",
    "epi_images_sliced_train_val = [epi_img for i, epi_img in enumerate(epi_images_sliced) if i != TEST_PARTICIPANT]\n",
    "\n",
    "epi_images_sliced_val = [epi_images_sliced_train_val[VAL_PARTICIPANT]]\n",
    "epi_images_sliced_train = [epi_img for i, epi_img in enumerate(epi_images_sliced_train_val) if i != VAL_PARTICIPANT]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding images\n",
    "\n",
    "The EPI volumes contained a varying amount of slices in the third dimension. Padding the volumes to match the LS volumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 42, 52)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epi_images_sliced_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_label(image):\n",
    "    \"\"\" \n",
    "    Resizing the label to match dimensions of the input data. Resized by zero-padding the third dimension.\n",
    "\n",
    "    Parameters:\n",
    "    - image: Image to be resized\n",
    "\n",
    "    Returns:\n",
    "    - resized_image: Image after zero-padding\n",
    "    \"\"\"\n",
    "    current_shape = image.shape[2]\n",
    "    desired_shape = 64 - current_shape\n",
    "    padded_image = np.pad(image, ((0,0), (0,0), (0, desired_shape), (0,0)), mode='constant')\n",
    "\n",
    "    flipped_image = np.fliplr(padded_image)\n",
    "    image = flipped_image.copy()\n",
    "    resized_image = torch.Tensor(image)\n",
    "\n",
    "    # Reshape to be the same shape as input image\n",
    "    resized_image = resized_image.permute(3,0,1,2) \n",
    "    resized_image = resized_image.unsqueeze(0) # add channel dimension    \n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epi_images_resized_train = [resize_label(image) for image in epi_images_sliced_train]\n",
    "epi_images_resized_val = [resize_label(image) for image in epi_images_sliced_val]\n",
    "epi_images_resized_test = [resize_label(image) for image in epi_images_sliced_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean X data: 284.45147705078125, Std X data: 710.0986328125\n"
     ]
    }
   ],
   "source": [
    "# Calculating mean and std on training data for normalization\n",
    "\n",
    "mean_epi, std_epi = calc_mean_std_tensor(epi_images_resized_train)\n",
    "\n",
    "print(f'Mean X data: {mean_epi}, Std X data: {std_epi}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_save_epi(images, save_path):\n",
    "    \"\"\" \n",
    "    Preprocessing and saving EPI images.\n",
    "\n",
    "    Parameters:\n",
    "    - images: EPI images to be preprocessed\n",
    "    - save_path: Path to save the preprocessed images.\n",
    "\n",
    "    Returns:\n",
    "    None. The images gets saved to specified folders.\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    for image in images:\n",
    "        preprocessed_image = preprocess_scale_epi(image, mean_epi, std_epi, normalize=True)\n",
    "        file_path = os.path.join(save_path, f'preprocessed{i}.pt')\n",
    "        torch.save(preprocessed_image, file_path)\n",
    "        i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing shape to ensure all images were padded correctly\n",
    "\n",
    "epi_train_path = '../preprocessed_4d/epi_train'\n",
    "preprocess_and_save_epi(epi_images_resized_train, epi_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epi_val_path = '../preprocessed_4d/epi_val'\n",
    "preprocess_and_save_epi(epi_images_resized_val, epi_val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epi_test_path = '../preprocessed_4d/epi_test'\n",
    "preprocess_and_save_epi(epi_images_resized_test, epi_test_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Master_Caroline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
